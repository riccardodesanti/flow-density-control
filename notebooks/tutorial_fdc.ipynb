{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88fd123a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from genexp.models import DiffusionModel\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "\n",
    "from genexp.sampling import VPSDE, EulerMaruyamaSampler\n",
    "from genexp.trainers.genexp import FDCTrainerFlow\n",
    "from genexp.utils import seed_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b67da5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightningDiffusion(LightningModule):\n",
    "    def __init__(self, model: DiffusionModel):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    \n",
    "    def forward(self, *args, **kwargs):\n",
    "        return self.model(*args, **kwargs)\n",
    "    \n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x0, = batch\n",
    "        t = torch.rand(x0.shape[0]).to(x0.device)\n",
    "        alpha, sig = self.model.sde.get_alpha_sigma(t[:, None])\n",
    "        eps = torch.randn(x0.shape).to(x0.device)\n",
    "\n",
    "        xt = torch.sqrt(alpha) * x0 + sig * eps\n",
    "\n",
    "        eps_pred = self(xt, t[:, None])\n",
    "\n",
    "        loss = torch.mean((eps - eps_pred)**2) / 2.\n",
    "        self.log('loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e8345c",
   "metadata": {},
   "source": [
    "## Training base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ce1317f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type           | Params | Mode \n",
      "-------------------------------------------------\n",
      "0 | model | DiffusionModel | 396 K  | train\n",
      "-------------------------------------------------\n",
      "396 K     Trainable params\n",
      "0         Non-trainable params\n",
      "396 K     Total params\n",
      "1.586     Total estimated model params size (MB)\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7a57fae6e47471c9e37f114248ad4fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/software/stacks/2024-06/spack/opt/spack/linux-ubuntu22.04-x86_64_v3/gcc-12.2.0/python-3.9.18-djnolup5uvd3ftcqzbfbfsc5b5lfls3b/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "x0 = torch.randn((50000, 2))\n",
    "x1 = torch.randn((5000, 2)) * 0.3 + 3\n",
    "dataset = torch.vstack((x0, x1))\n",
    "\n",
    "network = nn.Sequential(\n",
    "    nn.Linear(3, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 2)\n",
    ")\n",
    "\n",
    "sde = VPSDE(0.1, 12)\n",
    "\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = DiffusionModel(network, sde).to(device)\n",
    "pl_model = LightningDiffusion(model)\n",
    "\n",
    "\n",
    "dl = DataLoader(TensorDataset(dataset), batch_size=128, shuffle=True)\n",
    "\n",
    "trainer = Trainer(max_epochs=10)\n",
    "trainer.fit(pl_model, dl)\n",
    "torch.save(model.model.state_dict(), 'gauss_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6196becc",
   "metadata": {},
   "source": [
    "## Loading base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07b104d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = nn.Sequential(\n",
    "    nn.Linear(3, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 2)\n",
    ")\n",
    "\n",
    "sde = VPSDE(0.1, 12)\n",
    "\n",
    "model = DiffusionModel(network, sde)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.model.load_state_dict(torch.load('../models/gauss_model.pth', map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfad164",
   "metadata": {},
   "source": [
    "## Visualizing Pre-trained Density "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c187bf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = EulerMaruyamaSampler(model.to(device), data_shape=(2,), device=device)\n",
    "\n",
    "samples = []\n",
    "batch_size = 128\n",
    "num_samples = 50000\n",
    "for i in tqdm(range(num_samples // batch_size + 1)):\n",
    "    trajs, ts = sampler.sample_trajectories(N=batch_size, T=1000, device=device)\n",
    "    samples.append(trajs[-1].full.detach().cpu())\n",
    "\n",
    "samples = torch.vstack(samples)[:num_samples]\n",
    "\n",
    "x0 = torch.randn((50000, 2))\n",
    "x1 = torch.randn((5000, 2)) * 0.3 + 3\n",
    "dataset = torch.vstack((x0, x1))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "ax[0].hist(dataset[:, 0], bins=150)\n",
    "ax[1].hist(samples[:, 0].detach().cpu(), bins=100)\n",
    "ax[0].set_title('Data density')\n",
    "ax[1].set_title('Pre-trained model density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7043396",
   "metadata": {},
   "source": [
    "## Fine-tuning with FDC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ec5aa2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mnum_md_iterations)):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39madjoint_matching\u001b[38;5;241m.\u001b[39mnum_iterations):\n\u001b[0;32m---> 14\u001b[0m         am_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mfdc_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m         fdc_trainer\u001b[38;5;241m.\u001b[39mfinetune(am_dataset, steps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39madjoint_matching\u001b[38;5;241m.\u001b[39mfinetune_steps)\n\u001b[1;32m     17\u001b[0m     fdc_trainer\u001b[38;5;241m.\u001b[39mupdate_base_model()\n",
      "File \u001b[0;32m/cluster/project/krause/kprotopapas/generative-exploration/src/genexp/trainers/adjoint_matching.py:247\u001b[0m, in \u001b[0;36mAMTrainerFlow.generate_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    244\u001b[0m     trajectories, ts, sigmas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_trajectories()\n\u001b[1;32m    246\u001b[0m \u001b[38;5;66;03m# graph_trajectories is a list of the intermediate graphs\u001b[39;00m\n\u001b[0;32m--> 247\u001b[0m solver_info \u001b[38;5;241m=\u001b[39m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrajectories\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrajectories\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# add sigma_t to solver_info\u001b[39;00m\n\u001b[1;32m    249\u001b[0m solver_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmas\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m sigmas\n",
      "File \u001b[0;32m/cluster/project/krause/kprotopapas/generative-exploration/src/genexp/trainers/adjoint_matching.py:68\u001b[0m, in \u001b[0;36mLeanAdjointSolverFlow.solve\u001b[0;34m(self, trajectories, ts)\u001b[0m\n\u001b[1;32m     66\u001b[0m alpha \u001b[38;5;241m=\u001b[39m alpha_s[i]\n\u001b[1;32m     67\u001b[0m alpha_dot \u001b[38;5;241m=\u001b[39m alpha_dot_s[i]\n\u001b[0;32m---> 68\u001b[0m adj, v_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43madj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_t\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha_dot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha_dot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m trajs_adj\u001b[38;5;241m.\u001b[39mappend(adj\u001b[38;5;241m.\u001b[39mdetach())\n\u001b[1;32m     70\u001b[0m traj_v_pred\u001b[38;5;241m.\u001b[39mappend(v_pred\u001b[38;5;241m.\u001b[39mdetach())\n",
      "File \u001b[0;32m/cluster/project/krause/kprotopapas/generative-exploration/src/genexp/trainers/adjoint_matching.py:33\u001b[0m, in \u001b[0;36mLeanAdjointSolverFlow.step\u001b[0;34m(self, adj, x_t, t, alpha, alpha_dot, dt)\u001b[0m\n\u001b[1;32m     30\u001b[0m     eps_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m v_pred \u001b[38;5;241m-\u001b[39m alpha_dot\u001b[38;5;241m/\u001b[39m(alpha \u001b[38;5;241m+\u001b[39m dt) \u001b[38;5;241m*\u001b[39m x_t\u001b[38;5;241m.\u001b[39madjoint\n\u001b[1;32m     32\u001b[0m     g_term \u001b[38;5;241m=\u001b[39m (adj_t \u001b[38;5;241m*\u001b[39m eps_pred)\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m---> 33\u001b[0m     v \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg_term\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madjoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m v\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m x_t\u001b[38;5;241m.\u001b[39madjoint\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     37\u001b[0m adj_tmh \u001b[38;5;241m=\u001b[39m adj_t \u001b[38;5;241m+\u001b[39m dt \u001b[38;5;241m*\u001b[39m v\n",
      "File \u001b[0;32m/cluster/software/stacks/2024-06/spack/opt/spack/linux-ubuntu22.04-x86_64_v3/gcc-12.2.0/python-3.9.18-djnolup5uvd3ftcqzbfbfsc5b5lfls3b/lib/python3.9/site-packages/torch/autograd/__init__.py:412\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[1;32m    408\u001b[0m     result \u001b[38;5;241m=\u001b[39m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[1;32m    409\u001b[0m         grad_outputs_\n\u001b[1;32m    410\u001b[0m     )\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 412\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    423\u001b[0m         result[i] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor_like(inputs[i])\n\u001b[1;32m    424\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs))\n\u001b[1;32m    425\u001b[0m     ):\n",
      "File \u001b[0;32m/cluster/software/stacks/2024-06/spack/opt/spack/linux-ubuntu22.04-x86_64_v3/gcc-12.2.0/python-3.9.18-djnolup5uvd3ftcqzbfbfsc5b5lfls3b/lib/python3.9/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "import copy\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "config = OmegaConf.load('../configs/example_fdc.yaml')\n",
    "sampler = EulerMaruyamaSampler(model, data_shape=(2,), device=device)\n",
    "model = model.to(device)\n",
    "\n",
    "seed_everything(config.seed)\n",
    "fdc_trainer = FDCTrainerFlow(config, copy.deepcopy(model), copy.deepcopy(model), device=device, sampler=sampler)\n",
    "\n",
    "for k in tqdm(range(config.num_md_iterations)):\n",
    "    for i in range(config.adjoint_matching.num_iterations):\n",
    "        am_dataset = fdc_trainer.generate_dataset()\n",
    "        fdc_trainer.finetune(am_dataset, steps=config.adjoint_matching.finetune_steps)\n",
    "\n",
    "    fdc_trainer.update_base_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3173d7e2",
   "metadata": {},
   "source": [
    "## Visualizing Fine-tuned Model's Density "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd6c2ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'tuple' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m samples \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mvstack(samples)\n\u001b[1;32m     10\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[0;32m---> 11\u001b[0m ax[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mhist(\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m, bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m)\n\u001b[1;32m     12\u001b[0m ax[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mhist(samples[:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu(), bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m     13\u001b[0m ax[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData density\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/cluster/software/stacks/2024-06/spack/opt/spack/linux-ubuntu22.04-x86_64_v3/gcc-12.2.0/python-3.9.18-djnolup5uvd3ftcqzbfbfsc5b5lfls3b/lib/python3.9/site-packages/torch/utils/data/dataset.py:337\u001b[0m, in \u001b[0;36mConcatDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m--> 337\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m:\n\u001b[1;32m    338\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m-\u001b[39midx \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    339\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    340\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabsolute value of index should not exceed dataset length\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    341\u001b[0m             )\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'tuple' and 'int'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sampler = EulerMaruyamaSampler(fdc_trainer.fine_model.to(device), data_shape=(2,), device=device)\n",
    "\n",
    "samples_fdc = []\n",
    "for i in range(num_samples // batch_size + 1):\n",
    "    trajs, ts = sampler.sample_trajectories(N=batch_size, T=1000, device=device)\n",
    "    samples_fdc.append(trajs[-1].full.detach().cpu())\n",
    "\n",
    "samples_fdc = torch.vstack(samples_fdc)[:num_samples]\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(10, 4))\n",
    "ax[0].hist(dataset[:, 0], bins=150)\n",
    "ax[1].hist(samples[:, 0].detach().cpu(), bins=150)\n",
    "ax[2].hist(samples_fdc[:, 0].detach().cpu(), bins=150)\n",
    "ax[0].set_title('Data density')\n",
    "ax[1].set_title('Pre-trained model density')\n",
    "ax[2].set_title('Fine-tuned model density')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
