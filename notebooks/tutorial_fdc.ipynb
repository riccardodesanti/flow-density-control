{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88fd123a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-03 16:09:11.770081: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-03 16:09:11.799350: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-12-03 16:09:11.799390: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-12-03 16:09:11.800416: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-12-03 16:09:11.806315: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-03 16:09:12.943989: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x14717607af70>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/cluster/software/stacks/2024-06/spack/opt/spack/linux-ubuntu22.04-x86_64_v3/gcc-12.2.0/python-3.9.18-djnolup5uvd3ftcqzbfbfsc5b5lfls3b/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_swiss_roll, make_moons\n",
    "from matplotlib import pyplot as plt\n",
    "from genexp.models import DiffusionModel\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.loggers.tensorboard import TensorBoardLogger\n",
    "\n",
    "from genexp.sampling import VPSDE, sample_trajectories_ddpm, sample_trajectories_memoryless, EMDiffusionSampler, DDIMSampler, EulerMaruyamaSampler, MemorylessSampler\n",
    "from genexp.trainers.adjoint_matching import AMTrainerFlow\n",
    "from genexp.trainers.genexp import FDCTrainerFlow\n",
    "\n",
    "from matplotlib.widgets import Button, Slider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b67da5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightningDiffusion(LightningModule):\n",
    "    def __init__(self, model: DiffusionModel):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    \n",
    "    def forward(self, *args, **kwargs):\n",
    "        return self.model(*args, **kwargs)\n",
    "    \n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x0, = batch\n",
    "        t = torch.rand(x0.shape[0]).to(x0.device)\n",
    "        alpha, sig = self.model.sde.get_alpha_sigma(t[:, None])\n",
    "        eps = torch.randn(x0.shape).to(x0.device)\n",
    "\n",
    "        xt = torch.sqrt(alpha) * x0 + sig * eps\n",
    "\n",
    "        eps_pred = self(xt, t[:, None])\n",
    "\n",
    "        loss = torch.mean((eps - eps_pred)**2) / 2.\n",
    "        self.log('loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e8345c",
   "metadata": {},
   "source": [
    "## Training base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ce1317f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type           | Params | Mode \n",
      "-------------------------------------------------\n",
      "0 | model | DiffusionModel | 396 K  | train\n",
      "-------------------------------------------------\n",
      "396 K     Trainable params\n",
      "0         Non-trainable params\n",
      "396 K     Total params\n",
      "1.586     Total estimated model params size (MB)\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7a57fae6e47471c9e37f114248ad4fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/software/stacks/2024-06/spack/opt/spack/linux-ubuntu22.04-x86_64_v3/gcc-12.2.0/python-3.9.18-djnolup5uvd3ftcqzbfbfsc5b5lfls3b/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "x0 = torch.randn((50000, 2))\n",
    "x1 = torch.randn((5000, 2)) * 0.3 + 3\n",
    "dataset = torch.vstack((x0, x1))\n",
    "\n",
    "network = nn.Sequential(\n",
    "    nn.Linear(3, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 2)\n",
    ")\n",
    "\n",
    "sde = VPSDE(0.1, 12)\n",
    "\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = DiffusionModel(network, sde).to(device)\n",
    "pl_model = LightningDiffusion(model)\n",
    "\n",
    "\n",
    "dl = DataLoader(TensorDataset(dataset), batch_size=128, shuffle=True)\n",
    "\n",
    "trainer = Trainer(max_epochs=10)\n",
    "trainer.fit(pl_model, dl)\n",
    "torch.save(model.model.state_dict(), 'gauss_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a1a5ff",
   "metadata": {},
   "source": [
    "## Loading base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07b104d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 16.00 MiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m samples \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m50000\u001b[39m \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m128\u001b[39m):\n\u001b[0;32m---> 26\u001b[0m     trajs, ts \u001b[38;5;241m=\u001b[39m \u001b[43msampler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_trajectories\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8192\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     samples\u001b[38;5;241m.\u001b[39mappend(trajs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mfull\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu())\n\u001b[1;32m     29\u001b[0m samples \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mvstack(samples)\n",
      "File \u001b[0;32m/cluster/project/krause/kprotopapas/generative-exploration/src/genexp/sampling.py:383\u001b[0m, in \u001b[0;36mSampler.sample_trajectories\u001b[0;34m(self, N, T, sample_jumps, device)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;66;03m# order the ts ascending\u001b[39;00m\n\u001b[1;32m    381\u001b[0m     ts \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msort(ts, descending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(x0\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 383\u001b[0m xts, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore_traj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m traj \u001b[38;5;241m=\u001b[39m info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraj\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    385\u001b[0m traj \u001b[38;5;241m=\u001b[39m [Sample(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m traj]\n",
      "File \u001b[0;32m/cluster/project/krause/kprotopapas/generative-exploration/src/genexp/sampling.py:20\u001b[0m, in \u001b[0;36mSolver.solve\u001b[0;34m(self, x0, ts, steps, store_traj, device)\u001b[0m\n\u001b[1;32m     18\u001b[0m xt \u001b[38;5;241m=\u001b[39m x0\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t, tph \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(ts[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], ts[\u001b[38;5;241m1\u001b[39m:]):\n\u001b[0;32m---> 20\u001b[0m     xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m traj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m         traj\u001b[38;5;241m.\u001b[39mappend(xt)\n",
      "File \u001b[0;32m/cluster/project/krause/kprotopapas/generative-exploration/src/genexp/sampling.py:198\u001b[0m, in \u001b[0;36mEulerMaruyamaSolver.step\u001b[0;34m(self, xt, t, tph)\u001b[0m\n\u001b[1;32m    196\u001b[0m st \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnoise_func(t)\n\u001b[1;32m    197\u001b[0m et \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn_like(xt)\u001b[38;5;241m.\u001b[39mto(xt\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 198\u001b[0m score_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m etat \u001b[38;5;241m=\u001b[39m beta_t \u001b[38;5;241m*\u001b[39m (kt \u001b[38;5;241m*\u001b[39m beta_t \u001b[38;5;241m-\u001b[39m beta_dot_t)\n\u001b[1;32m    200\u001b[0m xtph \u001b[38;5;241m=\u001b[39m xt \u001b[38;5;241m+\u001b[39m h \u001b[38;5;241m*\u001b[39m kt \u001b[38;5;241m*\u001b[39m xt \u001b[38;5;241m+\u001b[39m h \u001b[38;5;241m*\u001b[39m (st\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m etat) \u001b[38;5;241m*\u001b[39m score_t \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(h) \u001b[38;5;241m*\u001b[39m st \u001b[38;5;241m*\u001b[39m et\n",
      "File \u001b[0;32m/cluster/project/krause/kprotopapas/generative-exploration/src/genexp/models.py:193\u001b[0m, in \u001b[0;36mDiffusionModel.score_func\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscore_func\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor, t: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    189\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03m    Diffusion models predict the error function by default, with time going from 1 (noise) to 0 (data)\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;124;03m    Instead we want time to go from 0 (noise) to 1 (data)\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m     eps_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m     _, sigma \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msde\u001b[38;5;241m.\u001b[39mget_alpha_sigma(\u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m-\u001b[39m t)\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39meps_pred\u001b[38;5;241m/\u001b[39msigma\u001b[38;5;241m.\u001b[39mto(eps_pred\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mto(eps_pred\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[0;32m/cluster/project/krause/kprotopapas/generative-exploration/src/genexp/models.py:69\u001b[0m, in \u001b[0;36mFlowModel.forward\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(t) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(x):\n\u001b[1;32m     67\u001b[0m     t \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mexpand(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cluster/software/stacks/2024-06/spack/opt/spack/linux-ubuntu22.04-x86_64_v3/gcc-12.2.0/python-3.9.18-djnolup5uvd3ftcqzbfbfsc5b5lfls3b/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cluster/software/stacks/2024-06/spack/opt/spack/linux-ubuntu22.04-x86_64_v3/gcc-12.2.0/python-3.9.18-djnolup5uvd3ftcqzbfbfsc5b5lfls3b/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/cluster/software/stacks/2024-06/spack/opt/spack/linux-ubuntu22.04-x86_64_v3/gcc-12.2.0/python-3.9.18-djnolup5uvd3ftcqzbfbfsc5b5lfls3b/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/cluster/software/stacks/2024-06/spack/opt/spack/linux-ubuntu22.04-x86_64_v3/gcc-12.2.0/python-3.9.18-djnolup5uvd3ftcqzbfbfsc5b5lfls3b/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cluster/software/stacks/2024-06/spack/opt/spack/linux-ubuntu22.04-x86_64_v3/gcc-12.2.0/python-3.9.18-djnolup5uvd3ftcqzbfbfsc5b5lfls3b/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/cluster/software/stacks/2024-06/spack/opt/spack/linux-ubuntu22.04-x86_64_v3/gcc-12.2.0/python-3.9.18-djnolup5uvd3ftcqzbfbfsc5b5lfls3b/lib/python3.9/site-packages/torch/nn/modules/activation.py:103\u001b[0m, in \u001b[0;36mReLU.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cluster/software/stacks/2024-06/spack/opt/spack/linux-ubuntu22.04-x86_64_v3/gcc-12.2.0/python-3.9.18-djnolup5uvd3ftcqzbfbfsc5b5lfls3b/lib/python3.9/site-packages/torch/nn/functional.py:1500\u001b[0m, in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1498\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 16.00 MiB. GPU "
     ]
    }
   ],
   "source": [
    "x0 = torch.randn((50000, 2))\n",
    "x1 = torch.randn((5000, 2)) * 0.3 + 3\n",
    "dataset = torch.vstack((x0, x1))\n",
    "\n",
    "network = nn.Sequential(\n",
    "    nn.Linear(3, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 2)\n",
    ")\n",
    "\n",
    "sde = VPSDE(0.1, 12)\n",
    "\n",
    "model = DiffusionModel(network, sde)\n",
    "pl_model = LightningDiffusion(model)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.model.load_state_dict(torch.load('gauss_model.pth'))\n",
    "sampler = EulerMaruyamaSampler(model.to(device), data_shape=(2,), device=device)\n",
    "\n",
    "samples = []\n",
    "for i in range(50000 // 128):\n",
    "    trajs, ts = sampler.sample_trajectories(N=8192, T=1000, device=device)\n",
    "    samples.append(trajs[-1].full.detach().cpu())\n",
    "\n",
    "samples = torch.vstack(samples)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "ax[0].hist(dataset[:, 0], bins=150)\n",
    "ax[1].hist(samples[:, 0].detach().cpu(), bins=100)\n",
    "ax[0].set_title('Data density')\n",
    "ax[1].set_title('Pretrained model density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ec5aa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "import copy\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "config = OmegaConf.load('../configs/example_fdc.yaml')\n",
    "sampler = EulerMaruyamaSampler(model, data_shape=(2,), device=device)\n",
    "model = model.to(device)\n",
    "fdc_trainer = FDCTrainerFlow(config, copy.deepcopy(model), copy.deepcopy(model), device=device, sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f373a10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:51<00:00, 17.33s/it]\n"
     ]
    }
   ],
   "source": [
    "for k in tqdm(range(config.num_md_iterations)):\n",
    "    for i in range(config.adjoint_matching.num_iterations):\n",
    "        am_dataset = fdc_trainer.generate_dataset()\n",
    "        fdc_trainer.finetune(am_dataset, steps=config.adjoint_matching.finetune_steps)\n",
    "\n",
    "    fdc_trainer.update_base_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebd6c2ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'tuple' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m samples \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mvstack(samples)\n\u001b[1;32m     10\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[0;32m---> 11\u001b[0m ax[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mhist(\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m, bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m)\n\u001b[1;32m     12\u001b[0m ax[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mhist(samples[:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu(), bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m     13\u001b[0m ax[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData density\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/cluster/software/stacks/2024-06/spack/opt/spack/linux-ubuntu22.04-x86_64_v3/gcc-12.2.0/python-3.9.18-djnolup5uvd3ftcqzbfbfsc5b5lfls3b/lib/python3.9/site-packages/torch/utils/data/dataset.py:337\u001b[0m, in \u001b[0;36mConcatDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m--> 337\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m:\n\u001b[1;32m    338\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m-\u001b[39midx \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    339\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    340\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabsolute value of index should not exceed dataset length\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    341\u001b[0m             )\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'tuple' and 'int'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sampler = EulerMaruyamaSampler(fdc_trainer.fine_model.to(device), data_shape=(2,), device=device)\n",
    "\n",
    "samples_fdc = []\n",
    "for i in range(50000 // 128):\n",
    "    trajs, ts = sampler.sample_trajectories(N=128, T=1000, device=device)\n",
    "    samples_fdc.append(trajs[-1].full.detach().cpu())\n",
    "\n",
    "samples_fdc = torch.vstack(samples_fdc)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(10, 4))\n",
    "ax[0].hist(dataset[:, 0], bins=150)\n",
    "ax[1].hist(samples_fdc[:, 0].detach().cpu(), bins=150)\n",
    "ax[0].set_title('Data density')\n",
    "ax[1].set_title('Fine-tuned model density')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ammols",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
